{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsnam95/my/blob/main/cluster_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Document Clustering with Python"
      ],
      "metadata": {
        "id": "CygnJNw2X5eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import os\n",
        "import codecs\n",
        "from sklearn import feature_extraction\n",
        "!pip install mpld3\n",
        "import mpld3\n",
        "import requests"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mpld3\n",
            "  Downloading mpld3-0.5.9-py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.2/201.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mpld3) (3.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from mpld3) (3.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->mpld3) (2.1.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mpld3) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mpld3) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mpld3) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mpld3) (4.39.3)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mpld3) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mpld3) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mpld3) (8.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mpld3) (0.11.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mpld3) (1.0.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mpld3) (1.16.0)\n",
            "Installing collected packages: mpld3\n",
            "Successfully installed mpld3-0.5.9\n"
          ]
        }
      ],
      "metadata": {
        "id": "mJXJ1Sk2X5et",
        "outputId": "23176a0a-9a47-4771-ae45-b1f24d315dae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1
    },
    {
      "cell_type": "markdown",
      "source": [
        "## preparing information"
      ],
      "metadata": {
        "id": "mVpQBp8gX5eu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "titles"
      ],
      "metadata": {
        "id": "53DJ8ctK5CI-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/brandomr/document_cluster/master/title_list.txt\"\n",
        "titles = requests.get(url).text.split('\\n')\n",
        "titles = titles[:100]\n",
        "titles"
      ],
      "outputs": [],
      "metadata": {
        "id": "YhI2gxBTX5eu"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "synopses(wiki) uncleaned"
      ],
      "metadata": {
        "id": "en0J649C5ISH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/brandomr/document_cluster/master/synopses_list_wiki.txt\"\n",
        "synopses_wiki = requests.get(url).text.split('\\n BREAKS HERE')\n",
        "synopses_wiki = synopses_wiki[:100]\n",
        "synopses_wiki"
      ],
      "metadata": {
        "id": "1uag7M5nJOaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cleaning synopses(wiki)"
      ],
      "metadata": {
        "id": "X1SNMlC25PXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "synopses_clean_wiki = []\n",
        "for text in synopses_wiki:\n",
        "    text = BeautifulSoup(text, 'html.parser').getText()\n",
        "    #strips html formatting and converts to unicode\n",
        "    synopses_clean_wiki.append(text)\n",
        "\n",
        "synopses_wiki = synopses_clean_wiki"
      ],
      "metadata": {
        "id": "bm2E6ZMPj7F8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "genres"
      ],
      "metadata": {
        "id": "I204XM7h5b_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/brandomr/document_cluster/master/genres_list.txt\"\n",
        "genres = requests.get(url).text.split('\\n')\n",
        "genres = genres[:100]\n",
        "genres"
      ],
      "metadata": {
        "id": "OpVEI9DcJU8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "synopses(imdb) uncleaned"
      ],
      "metadata": {
        "id": "XNc3qU5U5h4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/brandomr/document_cluster/master/synopses_list_imdb.txt\"\n",
        "synopses_imdb = requests.get(url).text.split('\\n BREAKS HERE')\n",
        "synopses_imdb = synopses_imdb[:100]\n",
        "synopses_imdb"
      ],
      "outputs": [],
      "metadata": {
        "id": "JIe8zfjOX5ev"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "cleaning synopses(imdb)"
      ],
      "metadata": {
        "id": "Ec6YFbzq5mEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "synopses_clean_imdb = []\n",
        "for text in synopses_imdb:\n",
        "    text = BeautifulSoup(text, 'html.parser').getText()\n",
        "    #strips html formatting and converts to unicode\n",
        "    synopses_clean_imdb.append(text)\n",
        "synopses_imdb = synopses_clean_imdb"
      ],
      "metadata": {
        "id": "I5D4dvURk8js"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "combine wiki & imdb synopses"
      ],
      "metadata": {
        "id": "NdeELs1R5qjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "synopses = []\n",
        "for i in range(len(synopses_wiki)):\n",
        "    item = synopses_wiki[i] + synopses_imdb[i]\n",
        "    synopses.append(item)"
      ],
      "outputs": [],
      "metadata": {
        "id": "qBxlpX5WX5ew"
      },
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "# generates index for each item in the corpora (in this case it's just rank) and I'll use this for scoring later\n",
        "ranks = []\n",
        "for i in range(0,len(titles)):\n",
        "    ranks.append(i)"
      ],
      "outputs": [],
      "metadata": {
        "id": "rKDTJcq3X5ew"
      },
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "print(str(len(titles)) + ' titles')\n",
        "print(str(len(synopses)) + ' synopses')\n",
        "print(str(len(genres)) + ' genres')\n",
        "print(str(len(ranks)) + ' ranks')"
      ],
      "metadata": {
        "id": "R6rswjs_kZok",
        "outputId": "030ecd4b-daf0-4df5-b5f0-d3baa927f462",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 titles\n",
            "100 synopses\n",
            "100 genres\n",
            "100 ranks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean data"
      ],
      "metadata": {
        "id": "FT2bGDBWpQDd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "stop words"
      ],
      "metadata": {
        "id": "YKzNJ_RjX5ew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load nltk's English stopwords as variable called 'stopwords'\n",
        "nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('english')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8spOHk_X5ex",
        "outputId": "8e306a07-ae64-4175-89bb-8f6162b84410"
      },
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": [
        "stemming"
      ],
      "metadata": {
        "id": "P8y82RPSX5ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load nltk's SnowballStemmer as variabled 'stemmer'\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "43JPzCDKX5ex"
      },
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": [
        "tokenize with stemming vs. tokenize only\n"
      ],
      "metadata": {
        "id": "N-nFhvhvX5ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# here I define a tokenizer and stemmer which returns the set of stems in the text that it is passed\n",
        "def tokenize_and_stem(text):\n",
        "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
        "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
        "    filtered_tokens = []\n",
        "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
        "    for token in tokens:\n",
        "        if re.search('[a-zA-Z]', token):\n",
        "            filtered_tokens.append(token)\n",
        "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
        "    return stems\n",
        "\n",
        "def tokenize_only(text):\n",
        "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
        "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
        "    filtered_tokens = []\n",
        "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
        "    for token in tokens:\n",
        "        if re.search('[a-zA-Z]', token):\n",
        "            filtered_tokens.append(token)\n",
        "    return filtered_tokens"
      ],
      "outputs": [],
      "metadata": {
        "id": "litqG7S-X5ey"
      },
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "source": [
        "stemming/tokenizing and tokenizing functions to iterate over the list of synopses to create two vocabularies: one stemmed and one only tokenized. "
      ],
      "metadata": {
        "id": "NYUHHBvTX5ey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "totalvocab_stemmed = []\n",
        "totalvocab_tokenized = []\n",
        "for i in synopses:\n",
        "    allwords_stemmed = tokenize_and_stem(i)\n",
        "    totalvocab_stemmed.extend(allwords_stemmed)\n",
        "    \n",
        "    allwords_tokenized = tokenize_only(i)\n",
        "    totalvocab_tokenized.extend(allwords_tokenized)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeaKiYRRX5ey",
        "outputId": "289eb94f-8d5d-47aa-b770-c555b9dd1371"
      },
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)\n",
        "vocab_frame"
      ],
      "outputs": [],
      "metadata": {
        "id": "eUZOYgDOX5ez"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tf-idf and document similarity"
      ],
      "metadata": {
        "id": "nEoYbgnMX5ez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
        "                                 min_df=0.2, stop_words='english',\n",
        "                                 use_idf=True, tokenizer=tokenize_and_stem, ngram_range=(1,3))\n",
        "%time tfidf_matrix = tfidf_vectorizer.fit_transform(synopses)\n",
        "print(tfidf_matrix.shape)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 8.73 s, sys: 61.3 ms, total: 8.8 s\n",
            "Wall time: 8.88 s\n",
            "(100, 563)\n"
          ]
        }
      ],
      "metadata": {
        "id": "WbkJgpbXX5e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "539e4d56-244c-406e-a8f3-524ed769c61a"
      },
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": [
        "terms = tfidf_vectorizer.get_feature_names_out()"
      ],
      "outputs": [],
      "metadata": {
        "id": "pzybU1vpX5e0"
      },
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "dist = 1 - cosine_similarity(tfidf_matrix)"
      ],
      "outputs": [],
      "metadata": {
        "id": "AAkUj3bRX5e0"
      },
      "execution_count": 22
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-means clustering"
      ],
      "metadata": {
        "id": "vk7-2hoEX5e0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "num_clusters = 5\n",
        "km = KMeans(n_clusters=num_clusters)\n",
        "%time km.fit(tfidf_matrix)\n",
        "clusters = km.labels_.tolist()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 386 ms, sys: 4.92 ms, total: 391 ms\n",
            "Wall time: 417 ms\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX2WP0w8X5e1",
        "outputId": "bace34cb-aa42-4786-b944-d3162d0e11bb"
      },
      "execution_count": 23
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(km, 'doc_cluster.pkl')\n",
        "km = joblib.load('doc_cluster.pkl')\n",
        "clusters = km.labels_.tolist()"
      ],
      "outputs": [],
      "metadata": {
        "id": "3G73DX6dX5e1"
      },
      "execution_count": 24
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "films = { 'title': titles, 'rank': ranks, 'synopsis': synopses, 'cluster': clusters, 'genre': genres }\n",
        "frame = pd.DataFrame(films, index = [clusters] , columns = ['rank', 'title', 'cluster', 'genre'])"
      ],
      "outputs": [],
      "metadata": {
        "id": "AMBbBODFX5e1"
      },
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": [
        "frame['cluster'].value_counts()"
      ],
      "outputs": [],
      "metadata": {
        "id": "pwX6bp63X5e1"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = frame['rank'].groupby(frame['cluster'])\n",
        "grouped.mean()"
      ],
      "outputs": [],
      "metadata": {
        "id": "nK8VziiXX5e1"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "print(\"Top terms per cluster:\")\n",
        "print()\n",
        "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
        "for i in range(num_clusters):\n",
        "    print(\"Cluster %d words:\" % i, end='')\n",
        "    for ind in order_centroids[i, :6]:\n",
        "        print(' %s' % vocab_frame.loc[terms[ind].split(' ')].values.tolist()[0][0].encode('utf-8', 'ignore'), end=',')\n",
        "    print()\n",
        "    print()\n",
        "    print(\"Cluster %d titles:\" % i, end='')\n",
        "    for title in frame.loc[i]['title'].values.tolist():\n",
        "        print(' %s,' % title, end='')\n",
        "    print()\n",
        "    print()"
      ],
      "outputs": [],
      "metadata": {
        "id": "5H8-oxTjX5e1"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#This is purely to help export tables to html and to correct for my 0 start rank (so that Godfather is 1, not 0)\n",
        "frame['Rank'] = frame['rank'] + 1\n",
        "frame['Title'] = frame['title']"
      ],
      "outputs": [],
      "metadata": {
        "id": "Z47w7CMXX5e2"
      },
      "execution_count": 29
    },
    {
      "cell_type": "code",
      "source": [
        "#export tables to HTML\n",
        "print(frame[['Rank', 'Title']].loc[frame['cluster'] == 1].to_html(index=False))"
      ],
      "outputs": [],
      "metadata": {
        "id": "j81_IbcdX5e2"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multidimensional scaling"
      ],
      "metadata": {
        "id": "fB_MfatuX5e2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os  # for os.path.basename\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from sklearn.manifold import MDS\n",
        "\n",
        "MDS()\n",
        "# two components as we're plotting points in a two-dimensional plane\n",
        "# \"precomputed\" because we provide a distance matrix\n",
        "# we will also specify `random_state` so the plot is reproducible.\n",
        "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=1)\n",
        "pos = mds.fit_transform(dist)  # shape (n_components, n_samples)\n",
        "xs, ys = pos[:, 0], pos[:, 1]"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/manifold/_mds.py:299: FutureWarning: The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmSj4dOTX5e2",
        "outputId": "75ba724c-da1d-4edf-8bb4-0cf5cfcfa8a0"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#strip any proper nouns (NNP) or plural proper nouns (NNPS) from a text\n",
        "from nltk.tag import pos_tag\n",
        "def strip_proppers_POS(text):\n",
        "    tagged = pos_tag(text.split()) #use NLTK's part of speech tagger\n",
        "    non_propernouns = [word for word,pos in tagged if pos != 'NNP' and pos != 'NNPS']\n",
        "    return non_propernouns"
      ],
      "outputs": [],
      "metadata": {
        "id": "wFuEmfAZX5e3"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing document clusters"
      ],
      "metadata": {
        "id": "Y2KJOCQNX5e3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set up colors per clusters using a dict\n",
        "cluster_colors = {0: '#1b9e77', 1: '#d95f02', 2: '#7570b3', 3: '#e7298a', 4: '#66a61e'}\n",
        "\n",
        "#set up cluster names using a dict\n",
        "cluster_names = {0: 'Family, home, war', \n",
        "                 1: 'Police, killed, murders', \n",
        "                 2: 'Father, New York, brothers', \n",
        "                 3: 'Dance, singing, love', \n",
        "                 4: 'Killed, soldiers, captain'}"
      ],
      "outputs": [],
      "metadata": {
        "id": "VYl5k_4oX5e3"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "outputs": [],
      "metadata": {
        "id": "qmeXmKjjX5e3"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#create data frame that has the result of the MDS plus the cluster numbers and titles\n",
        "df = pd.DataFrame(dict(x=xs, y=ys, label=clusters, title=titles)) \n",
        "\n",
        "#group by cluster\n",
        "groups = df.groupby('label')\n",
        "\n",
        "# set up plot\n",
        "fig, ax = plt.subplots(figsize=(17, 9)) # set size\n",
        "ax.margins(0.05) # Optional, just adds 5% padding to the autoscaling\n",
        "\n",
        "#iterate through groups to layer the plot\n",
        "#note that I use the cluster_name and cluster_color dicts with the 'name' lookup to return the appropriate color/label\n",
        "for name, group in groups:\n",
        "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=cluster_names[name], color=cluster_colors[name], mec='none')\n",
        "    ax.set_aspect('auto')\n",
        "    ax.tick_params(\\\n",
        "        axis= 'x',          # changes apply to the x-axis\n",
        "        which='both',      # both major and minor ticks are affected\n",
        "        bottom='off',      # ticks along the bottom edge are off\n",
        "        top='off',         # ticks along the top edge are off\n",
        "        labelbottom='off')\n",
        "    ax.tick_params(\\\n",
        "        axis= 'y',         # changes apply to the y-axis\n",
        "        which='both',      # both major and minor ticks are affected\n",
        "        left='off',      # ticks along the bottom edge are off\n",
        "        top='off',         # ticks along the top edge are off\n",
        "        labelleft='off')\n",
        "    \n",
        "ax.legend(numpoints=1)  #show legend with only 1 point\n",
        "\n",
        "#add label in x,y position with the label as the film title\n",
        "for i in range(len(df)):\n",
        "    ax.text(df.loc[i]['x'], df.loc[i]['y'], df.loc[i]['title'], size=8)\n",
        "    \n",
        "plt.show() #show the plot\n",
        "\n",
        "#uncomment the below to save the plot if need be\n",
        "#plt.savefig('clusters_small_noaxes.png', dpi=200)"
      ],
      "outputs": [],
      "metadata": {
        "id": "QhbGPbfbX5e3"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.close()"
      ],
      "outputs": [],
      "metadata": {
        "id": "7v7VkPi1X5e3"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#define custom toolbar location\n",
        "class TopToolbar(mpld3.plugins.PluginBase):\n",
        "    \"\"\"Plugin for moving toolbar to top of figure\"\"\"\n",
        "\n",
        "    JAVASCRIPT = \"\"\"\n",
        "    mpld3.register_plugin(\"toptoolbar\", TopToolbar);\n",
        "    TopToolbar.prototype = Object.create(mpld3.Plugin.prototype);\n",
        "    TopToolbar.prototype.constructor = TopToolbar;\n",
        "    function TopToolbar(fig, props){\n",
        "        mpld3.Plugin.call(this, fig, props);\n",
        "    };\n",
        "\n",
        "    TopToolbar.prototype.draw = function(){\n",
        "      // the toolbar svg doesn't exist\n",
        "      // yet, so first draw it\n",
        "      this.fig.toolbar.draw();\n",
        "\n",
        "      // then change the y position to be\n",
        "      // at the top of the figure\n",
        "      this.fig.toolbar.toolbar.attr(\"x\", 150);\n",
        "      this.fig.toolbar.toolbar.attr(\"y\", 400);\n",
        "\n",
        "      // then remove the draw function,\n",
        "      // so that it is not called again\n",
        "      this.fig.toolbar.draw = function() {}\n",
        "    }\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.dict_ = {\"type\": \"toptoolbar\"}"
      ],
      "outputs": [],
      "metadata": {
        "id": "qYajJM-IX5e4"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#create data frame that has the result of the MDS plus the cluster numbers and titles\n",
        "df = pd.DataFrame(dict(x=xs, y=ys, label=clusters, title=titles)) \n",
        "\n",
        "#group by cluster\n",
        "groups = df.groupby('label')\n",
        "\n",
        "#define custom css to format the font and to remove the axis labeling\n",
        "css = \"\"\"\n",
        "text.mpld3-text, div.mpld3-tooltip {\n",
        "  font-family:Arial, Helvetica, sans-serif;\n",
        "}\n",
        "\n",
        "g.mpld3-xaxis, g.mpld3-yaxis {\n",
        "display: none; }\n",
        "\"\"\"\n",
        "\n",
        "# Plot \n",
        "fig, ax = plt.subplots(figsize=(14,6)) #set plot size\n",
        "ax.margins(0.03) # Optional, just adds 5% padding to the autoscaling\n",
        "\n",
        "#iterate through groups to layer the plot\n",
        "#note that I use the cluster_name and cluster_color dicts with the 'name' lookup to return the appropriate color/label\n",
        "for name, group in groups:\n",
        "    points = ax.plot(group.x, group.y, marker='o', linestyle='', ms=18, label=cluster_names[name], mec='none', color=cluster_colors[name])\n",
        "    ax.set_aspect('auto')\n",
        "    labels = [i for i in group.title]\n",
        "    \n",
        "    #set tooltip using points, labels and the already defined 'css'\n",
        "    tooltip = mpld3.plugins.PointHTMLTooltip(points[0], labels,\n",
        "                                       voffset=10, hoffset=10, css=css)\n",
        "    #connect tooltip to fig\n",
        "    mpld3.plugins.connect(fig, tooltip, TopToolbar())    \n",
        "    \n",
        "    #set tick marks as blank\n",
        "    ax.axes.get_xaxis().set_ticks([])\n",
        "    ax.axes.get_yaxis().set_ticks([])\n",
        "    \n",
        "    #set axis as blank\n",
        "    ax.axes.get_xaxis().set_visible(False)\n",
        "    ax.axes.get_yaxis().set_visible(False)\n",
        "\n",
        "    \n",
        "ax.legend(numpoints=1) #show legend with only one dot\n",
        "\n",
        "mpld3.display() #show the plot\n",
        "\n",
        "#uncomment the below to export to html\n",
        "#html = mpld3.fig_to_html(fig)\n",
        "#print(html)"
      ],
      "outputs": [],
      "metadata": {
        "id": "5WYjEEFwX5e4"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hierarchical document clustering"
      ],
      "metadata": {
        "id": "GWs-zRGTX5e4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.cluster.hierarchy import ward, dendrogram\n",
        "\n",
        "linkage_matrix = ward(dist) #define the linkage_matrix using ward clustering pre-computed distances\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(15, 20)) # set size\n",
        "ax = dendrogram(linkage_matrix, orientation=\"right\", labels=titles);\n",
        "\n",
        "plt.tick_params(\\\n",
        "    axis= 'x',          # changes apply to the x-axis\n",
        "    which='both',      # both major and minor ticks are affected\n",
        "    bottom='off',      # ticks along the bottom edge are off\n",
        "    top='off',         # ticks along the top edge are off\n",
        "    labelbottom='off')\n",
        "\n",
        "plt.tight_layout() #show plot with tight layout\n",
        "\n",
        "#uncomment below to save figure\n",
        "plt.savefig('ward_clusters.png', dpi=200) #save figure as ward_clusters"
      ],
      "outputs": [],
      "metadata": {
        "id": "jswzcrhJX5e4"
      },
      "execution_count": null
    }
  ]
}